{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This project analyzes pharmaceutical spending data obtained from the Organisation for Economic Co-operation and Development (OECD). The goal is to understand trends in pharmaceutical spending across various countries and to prepare the dataset for further analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "The data comes from the following sources:\n",
    "- **Pharmaceutical Spending Data**: [OECD](https://data.oecd.org/healthres/pharmaceutical-spending.htm)\n",
    "- **Population Data**: [DataHub](http://datahub.io/core/population)\n",
    "\n",
    "Additional details about the data fields:\n",
    "- **LOCATION**: Country code\n",
    "- **TIME**: Year of the data\n",
    "- **PC_HEALTHXP**: Percent of health spending\n",
    "- **PC_GDP**: Percent of GDP\n",
    "- **USD_CAP**: US dollars per capita\n",
    "- **FLAG_CODES**: Additional metadata flags\n",
    "- **TOTAL_SPEND**: Total pharmaceutical spending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps\n",
    "\n",
    "The data preprocessing includes the following steps:\n",
    "\n",
    "1. **Loading the Raw Dataset**\n",
    "   - Load the original CSV file into a DataFrame for initial inspection.\n",
    "\n",
    "2. **Creating a Copy for Processing**\n",
    "   - Make a copy of the raw DataFrame to preserve the original data.\n",
    "\n",
    "3. **Handling Missing Values**\n",
    "   - Fill missing values in the `FLAG_CODES` column with the placeholder `\"Unknown\"`.\n",
    "\n",
    "4. **Converting Data Types**\n",
    "   - Convert `LOCATION` to a string, `TIME` to an integer, and other numerical columns to floats to ensure consistency.\n",
    "\n",
    "5. **Saving the Processed Data**\n",
    "   - Save the cleaned and processed dataset in the `data/processed` directory for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress only FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>TIME</th>\n",
       "      <th>PC_HEALTHXP</th>\n",
       "      <th>PC_GDP</th>\n",
       "      <th>USD_CAP</th>\n",
       "      <th>FLAG_CODES</th>\n",
       "      <th>TOTAL_SPEND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1971</td>\n",
       "      <td>15.992</td>\n",
       "      <td>0.727</td>\n",
       "      <td>35.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1972</td>\n",
       "      <td>15.091</td>\n",
       "      <td>0.686</td>\n",
       "      <td>36.056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1973</td>\n",
       "      <td>15.117</td>\n",
       "      <td>0.681</td>\n",
       "      <td>39.871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1974</td>\n",
       "      <td>14.771</td>\n",
       "      <td>0.755</td>\n",
       "      <td>47.559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1975</td>\n",
       "      <td>11.849</td>\n",
       "      <td>0.682</td>\n",
       "      <td>47.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION  TIME  PC_HEALTHXP  PC_GDP  USD_CAP FLAG_CODES  TOTAL_SPEND\n",
       "0      AUS  1971       15.992   0.727   35.720        NaN       462.11\n",
       "1      AUS  1972       15.091   0.686   36.056        NaN       475.11\n",
       "2      AUS  1973       15.117   0.681   39.871        NaN       533.47\n",
       "3      AUS  1974       14.771   0.755   47.559        NaN       652.65\n",
       "4      AUS  1975       11.849   0.682   47.561        NaN       660.76"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to the CSV file\n",
    "file_path = 'data/raw/flat-ui__data-Fri Oct 18 2024.csv'\n",
    "\n",
    "# Load the raw dataset\n",
    "raw_df = pd.read_csv('data/raw/flat-ui__data-Fri Oct 18 2024.csv')\n",
    "\n",
    "# Save the original raw dataset to a standard location\n",
    "raw_df.to_csv('data/raw/raw_dataset.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 1036 observations (rows) and 7 variables (columns).\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns\n",
    "rows, columns = raw_df.shape\n",
    "\n",
    "# Print the results\n",
    "print (f'The dataset contains {rows} observations (rows) and {columns} variables (columns).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the FLAG_CODES column:\n",
      "[nan 'B' 'D' 'P']\n",
      "\n",
      "Counts of each value in the FLAG_CODES column:\n",
      "FLAG_CODES\n",
      "NaN    973\n",
      "B       46\n",
      "D       11\n",
      "P        6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display all unique values in the FLAG_CODES column, including NaN\n",
    "unique_flag_codes = raw_df['FLAG_CODES'].unique()\n",
    "print(\"Unique values in the FLAG_CODES column:\")\n",
    "print(unique_flag_codes)\n",
    "\n",
    "# Display the number of occurrences for each value in the FLAG_CODES column\n",
    "flag_code_counts = raw_df['FLAG_CODES'].value_counts(dropna=False)\n",
    "print(\"\\nCounts of each value in the FLAG_CODES column:\")\n",
    "print(flag_code_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in FLAG_CODES before filling: 973\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the raw dataset to work on as processed_df\n",
    "# This will ensure any processing happens on the copy, not altering the original raw data\n",
    "processed_df = raw_df.copy()\n",
    "\n",
    "# Check the current state of the FLAG_CODES column to see how many missing values there are\n",
    "missing_before = processed_df['FLAG_CODES'].isna().sum()\n",
    "print(f\"Missing values in FLAG_CODES before filling: {missing_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in FLAG_CODES after filling: 0\n",
      "Unique values in FLAG_CODES after filling: ['Unknown' 'B' 'D' 'P']\n"
     ]
    }
   ],
   "source": [
    "#  Fill missing values in the FLAG_CODES column with the placeholder \"Unknown\"\n",
    "processed_df['FLAG_CODES'] = processed_df['FLAG_CODES'].fillna('Unknown')\n",
    "\n",
    "#  Verify that there are no more missing values in the FLAG_CODES column\n",
    "missing_after = processed_df['FLAG_CODES'].isna().sum()\n",
    "print(f\"Missing values in FLAG_CODES after filling: {missing_after}\")\n",
    "\n",
    "# Display the unique values in the FLAG_CODES column to confirm the addition of \"Unknown\"\n",
    "unique_values = processed_df['FLAG_CODES'].unique()\n",
    "print(f\"Unique values in FLAG_CODES after filling: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      "LOCATION       0\n",
      "TIME           0\n",
      "PC_HEALTHXP    0\n",
      "PC_GDP         0\n",
      "USD_CAP        0\n",
      "FLAG_CODES     0\n",
      "TOTAL_SPEND    0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values Summary:\n",
      "LOCATION         36\n",
      "TIME             47\n",
      "PC_HEALTHXP    1009\n",
      "PC_GDP          756\n",
      "USD_CAP        1033\n",
      "FLAG_CODES        4\n",
      "TOTAL_SPEND    1036\n",
      "dtype: int64\n",
      "\n",
      "Unique values in LOCATION:\n",
      "['AUS' 'AUT' 'BEL' 'CAN' 'CHE' 'CZE' 'DEU' 'DNK' 'ESP' 'EST' 'FIN' 'FRA'\n",
      " 'GBR' 'GRC' 'HUN' 'IRL' 'ISL' 'ISR' 'ITA' 'JPN' 'KOR' 'LTU' 'LUX' 'LVA'\n",
      " 'MEX' 'NLD' 'NOR' 'NZL' 'POL' 'PRT' 'RUS' 'SVK' 'SVN' 'SWE' 'TUR' 'USA']\n",
      "\n",
      "Unique values in TIME:\n",
      "[1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984\n",
      " 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998\n",
      " 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012\n",
      " 2013 2014 2015 1970 2016]\n",
      "\n",
      "Unique values in PC_HEALTHXP:\n",
      "[15.992 15.091 15.117 ... 11.459 11.384 12.227]\n",
      "\n",
      "Unique values in PC_GDP:\n",
      "[0.727 0.686 0.681 0.755 0.682 0.63  0.613 0.591 0.523 0.54  0.548 0.564\n",
      " 0.58  0.569 0.599 0.582 0.595 0.623 0.677 0.739 0.778 0.819 0.859 0.882\n",
      " 0.924 0.95  1.019 1.075 1.194 1.236 1.213 1.244 1.269 1.219 1.225 1.273\n",
      " 1.334 1.324 1.315 1.336 1.32  1.306 0.784 0.78  0.801 0.84  0.852 0.854\n",
      " 0.876 1.01  1.087 1.17  1.174 1.198 1.238 1.304 1.294 1.277 1.268 1.289\n",
      " 1.311 1.271 1.251 1.234 1.245 1.28  1.078 1.109 1.126 1.2   1.183 1.208\n",
      " 1.081 1.133 1.135 1.106 1.068 1.053 1.045 1.084 1.017 1.074 1.102 1.136\n",
      " 1.147 1.103 1.157 1.237 1.347 1.313 1.351 1.327 1.332 1.557 1.536 1.472\n",
      " 1.493 1.532 1.59  1.555 1.547 1.487 1.48  1.44  1.489 0.76  0.762 0.716\n",
      " 0.679 0.611 0.609 0.589 0.583 0.635 0.704 0.72  0.763 0.842 0.884 0.932\n",
      " 1.    1.19  1.233 1.206 1.229 1.354 1.374 1.465 1.55  1.614 1.637 1.68\n",
      " 1.679 1.687 1.885 1.951 1.872 1.828 1.778 1.743 0.808 0.865 0.79  0.766\n",
      " 0.777 0.805 0.843 0.853 0.893 0.935 0.96  0.964 1.003 1.012 1.041 1.05\n",
      " 1.1   1.089 1.02  0.993 0.991 1.558 1.562 1.588 1.6   1.61  1.69  0.908\n",
      " 0.836 0.99  1.201 1.564 1.629 1.56  1.539 1.412 1.403 1.414 1.474 1.657\n",
      " 1.642 1.643 1.457 1.339 1.618 1.418 1.426 1.511 1.384 1.293 1.25  0.971\n",
      " 1.004 1.032 1.044 1.094 1.149 1.144 1.104 1.123 1.096 1.125 1.151 1.168\n",
      " 1.203 1.267 1.195 1.181 1.388 1.239 1.253 1.318 1.301 1.367 1.386 1.451\n",
      " 1.51  1.454 1.581 1.518 1.53  1.698 1.652 1.524 1.535 1.587 1.596 0.53\n",
      " 0.527 0.534 0.539 0.528 0.546 0.563 0.555 0.6   0.566 0.647 0.646 0.731\n",
      " 0.725 0.718 0.783 0.735 0.759 0.823 0.804 0.799 0.829 0.792 0.813 0.798\n",
      " 0.797 0.693 0.698 1.083 1.153 1.061 0.983 0.98  1.039 1.132 1.394 1.433\n",
      " 1.482 1.498 1.497 1.541 1.648 1.62  1.585 1.523 1.49  1.533 1.641 1.617\n",
      " 1.602 1.685 1.627 1.649 1.139 1.177 1.222 1.285 1.204 1.191 1.169 1.093\n",
      " 1.307 1.296 1.164 1.162 1.187 0.689 0.775 0.691 0.785 0.717 0.663 0.658\n",
      " 0.637 0.662 0.694 0.668 0.661 0.715 0.86  0.951 1.112 0.999 1.058 1.196\n",
      " 1.264 1.288 1.179 1.247 1.156 1.173 1.184 1.185 1.266 1.375 1.448 1.586\n",
      " 1.574 1.513 1.501 1.525 1.576 1.612 1.675 1.716 1.763 1.785 1.788 1.74\n",
      " 1.714 1.722 1.796 1.752 1.724 1.686 1.639 1.666 1.631 0.628 0.642 0.638\n",
      " 0.603 0.695 0.627 0.649 0.665 0.685 0.707 0.742 0.794 0.771 0.772 0.749\n",
      " 0.746 0.744 0.737 0.806 0.896 0.969 0.913 0.844 0.851 0.907 1.154 1.257\n",
      " 1.335 1.3   1.298 1.097 1.171 1.439 1.753 1.827 2.01  2.117 2.337 2.573\n",
      " 2.737 2.797 2.55  2.312 2.12  2.17  1.918 1.981 2.127 2.248 1.802 1.816\n",
      " 1.747 2.028 2.063 2.247 2.267 2.511 2.507 2.294 2.277 2.394 2.515 2.653\n",
      " 2.443 2.208 2.155 2.114 0.973 0.957 0.903 0.917 0.897 0.878 0.747 0.733\n",
      " 0.705 0.748 0.752 0.758 0.734 0.745 0.837 0.987 1.057 1.131 1.276 1.453\n",
      " 1.591 1.432 1.512 1.007 0.874 0.883 0.753 0.714 0.779 0.757 0.811 0.855\n",
      " 1.009 1.105 1.182 0.966 1.033 1.03  1.076 1.118 1.232 1.282 1.377 1.471\n",
      " 1.33  1.178 1.27  1.419 1.393 1.309 1.256 0.923 0.938 0.937 0.941 0.915\n",
      " 1.551 1.503 1.517 1.529 1.442 1.395 1.342 1.39  1.458 1.5   1.554 1.604\n",
      " 1.703 1.726 1.719 1.702 1.633 1.638 1.484 1.52  1.527 1.613 1.594 1.163\n",
      " 1.214 1.305 1.317 1.23  1.323 1.405 1.322 1.248 1.316 1.486 1.54  1.545\n",
      " 1.632 1.901 1.875 2.008 2.038 2.035 2.037 0.551 0.459 0.428 0.366 0.316\n",
      " 0.487 0.502 0.463 0.514 0.676 0.743 0.789 0.711 0.723 0.696 0.699 0.817\n",
      " 0.796 0.765 0.776 0.769 0.786 0.835 0.885 0.978 1.211 1.397 1.443 1.556\n",
      " 1.546 1.662 1.705 1.689 1.669 1.584 1.553 1.867 1.937 1.809 1.961 1.821\n",
      " 1.692 1.82  1.728 1.745 0.616 0.664 0.651 0.702 0.764 0.684 0.669 0.724\n",
      " 0.68  0.543 0.552 0.513 0.52  1.475 1.321 1.209 1.499 1.383 1.473 1.542\n",
      " 0.931 0.968 2.134 2.108 1.984 1.974 1.904 2.004 1.896 1.623 1.704 1.645\n",
      " 1.537 1.595 0.617 0.588 0.575 0.571 0.56  0.598 0.614 0.636 0.67  0.71\n",
      " 0.69  0.822 0.872 0.85  0.858 0.848 0.862 0.867 0.91  0.956 0.997 1.016\n",
      " 0.982 1.022 1.021 0.845 0.841 0.342 0.338 0.332 0.346 0.369 0.353 0.322\n",
      " 0.596 0.59  0.621 0.584 0.622 0.485 0.498 0.542 0.573 0.593 0.692 0.81\n",
      " 0.787 0.906 0.911 0.888 0.633 0.703 0.678 0.7   0.645 0.657 0.73  0.871\n",
      " 0.9   1.028 1.029 1.027 1.002 0.976 1.794 1.883 1.819 1.672 1.559 1.568\n",
      " 1.619 1.505 1.38  1.341 0.846 1.025 0.965 1.018 1.365 1.462 1.344 1.396\n",
      " 1.567 1.691 1.673 1.748 1.835 1.832 1.783 1.89  1.929 2.076 2.084 2.041\n",
      " 2.007 1.991 1.892 1.751 1.389 1.391 1.286 1.928 1.843 1.851 2.072 2.196\n",
      " 2.215 2.136 2.112 2.101 2.342 2.278 2.131 2.026 1.998 1.871 1.85  1.766\n",
      " 1.683 1.697 1.65  1.699 1.677 1.767 1.589 1.566 0.422 0.462 0.561 0.556\n",
      " 0.557 0.586 0.587 0.554 0.565 0.626 0.761 0.943 0.953 1.085 1.167 1.152\n",
      " 1.205 1.129 1.11  0.276 0.277 0.261 0.231 0.207 0.228 0.253 0.83  1.221\n",
      " 1.421 1.782 1.818 1.814 1.866 1.884 2.015 1.957 1.939 1.874 1.858 2.068]\n",
      "\n",
      "Unique values in USD_CAP:\n",
      "[  35.72    36.056   39.871 ...  980.864 1081.402 1162.399]\n",
      "\n",
      "Unique values in FLAG_CODES:\n",
      "['Unknown' 'B' 'D' 'P']\n",
      "\n",
      "Unique values in TOTAL_SPEND:\n",
      "[   462.11    475.11    533.47 ... 310154.01 344495.16 373009.91]\n"
     ]
    }
   ],
   "source": [
    "# Summary of missing values for each column\n",
    "missing_values_summary = processed_df.isna().sum()\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_values_summary)\n",
    "\n",
    "# Summary of unique values for each column\n",
    "unique_values_summary = processed_df.nunique()\n",
    "print(\"\\nUnique Values Summary:\")\n",
    "print(unique_values_summary)\n",
    "\n",
    "# Display the unique values for each column if you want to see what they are\n",
    "for column in processed_df.columns:\n",
    "    unique_values = processed_df[column].unique()\n",
    "    print(f\"\\nUnique values in {column}:\")\n",
    "    print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "processed_df['LOCATION'] = processed_df['LOCATION'].astype(str)\n",
    "processed_df['TIME'] = processed_df['TIME'].astype(int)\n",
    "processed_df['PC_HEALTHXP'] = processed_df['PC_HEALTHXP'].astype(float)\n",
    "processed_df['PC_GDP'] = processed_df['PC_GDP'].astype(float)\n",
    "processed_df['USD_CAP'] = processed_df['USD_CAP'].astype(float)\n",
    "processed_df['TOTAL_SPEND'] = processed_df['TOTAL_SPEND'].astype(float)\n",
    "\n",
    "\n",
    "# Save the processed DataFrame\n",
    "processed_df.to_csv('data/processed/processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Analysis\n",
    "\n",
    "In this section, we will perform simple linear regression to identify trends and patterns in the pharmaceutical spending data. We will focus on finding relationships between:\n",
    "1. `TIME` (Year) and `TOTAL_SPEND`: To analyze how total pharmaceutical spending has changed over time.\n",
    "2. `PC_HEALTHXP` (Percent of health spending) and `USD_CAP` (Spending per capita): To observe if there is a relationship between the percentage of health spending and the amount spent per person.\n",
    "3. `PC_GDP` (Percent of GDP) and `TOTAL_SPEND`: To see how pharmaceutical spending relates to the share of GDP allocated to health.\n",
    "\n",
    "We will use scatter plots with linear regression lines to visualize these relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After plotting the linear regression lines, the next steps will include:\n",
    "1. **Assessing the quality of the linear fit**: We will calculate R-squared values to measure how well the linear model fits the data.\n",
    "2. **Outlier detection**: Identify and analyze any outliers in the data.\n",
    "3. **More advanced modeling**: If linear trends are not strong, we may explore more complex models (e.g., polynomial regression or time-series forecasting).\n",
    "4. **Feature engineering**: Create new features that may better explain variations in the data, such as growth rates or moving averages.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
